import streamlit as st
from langchain.memory import ConversationSummaryBufferMemory
from langchain_core.runnables import RunnablePassthrough, RunnableLambda
from langchain_core.vectorstores import VectorStoreRetriever
from langchain_openai import ChatOpenAI

from components.langchain.callback_handler.streaming_chat_callback_handler import StreamingChatCallBackHandler
from components.langchain.init_llm import initialize_open_ai_llm
from components.langchain.init_memory import initialize_conversation_memory
from components.langchain.site_parser import parse_by_sitemap_xml_embedding
from components.pages.common.chat_message import print_message, print_message_history, print_message_and_save, \
    save_message
from components.pages.common.session import set_session, get_session
from components.pages.sitegpt.event import on_button_click
from components.pages.sitegpt.prompt import find_answer_prompt, pick_answer_prompt

st.set_page_config(
    page_title="SiteGPT",
    page_icon="ğŸ–¥ï¸",
)


# streaming=False ë¡œ ì„¤ì •ì‹œ StreamingChatCallBackHandler ì˜ on_llm_new_token event ëŠ” ì‘ë™ í•˜ì§€ ì•ŠìŒ
@st.cache_resource
def init_open_ai_streaming() -> ChatOpenAI:
    return initialize_open_ai_llm(streaming=True, callbacks=[StreamingChatCallBackHandler()])


@st.cache_resource
def init_open_ai() -> ChatOpenAI:
    return initialize_open_ai_llm()


non_streaming_llm = init_open_ai()
streaming_llm = init_open_ai_streaming()


@st.cache_resource(show_spinner="Fetching document by WebSite...")
def find_docs_by_sitemap(url_param: str, url_filter_param: str) -> VectorStoreRetriever:
    filter_arr = []

    if url_filter_param:
        filter_arr.append(fr"^(.*\/{url_filter_param}.*\/)")

    return parse_by_sitemap_xml_embedding(url_param, filter_arr)


@st.cache_resource
def init_memory() -> ConversationSummaryBufferMemory:
    return initialize_conversation_memory(chat_model=non_streaming_llm,
                                          memory_key='chat_history', return_messages=True)


memory = init_memory()


def __get_answers(inputs):
    docs = inputs["docs"]
    question = inputs["question"]
    answers_chain = RunnablePassthrough.assign(chat_history=__load_memory) | find_answer_prompt() | non_streaming_llm

    return {
        "question": question,
        "answers": [
            {
                "answer": __invoke_answer_chain(answers_chain, question, doc.page_content),
                "source": doc.metadata["source"],
                "date": 'None',
            } for doc in docs
        ]
    }


# _ -> ì‚¬ìš©ì ì˜ ì§ˆë¬¸ + context
def __load_memory(_):
    return memory.load_memory_variables({})["chat_history"]


def __invoke_answer_chain(chain_param, question, context):
    chain_result = chain_param.invoke(
        {"question": question, "context": context}
    )
    memory.save_context({"input": question}, {"output": chain_result.content})
    return chain_result


def __pick_answer(inputs):
    question = inputs["question"]
    answers = inputs["answers"]

    pick_chain = pick_answer_prompt() | streaming_llm

    condensed = "\n\n".join(f"Answer: {answer['answer']}\nSource: {answer['source']}\ndate: {answer['date']}\n"
                            for answer in answers)
    return pick_chain.invoke({
        "question": question,
        "answers": condensed
    })


st.title('SiteGPT')

st.markdown(
    """
    Ask Questions about the content of a website.
    
    Start by writing URL of the website on the sidebar
    """
)

# session state ëŠ” í˜ì´ì§€ ë¥¼ ë‹«ì§€ ì•ŠëŠ” ì´ìƒ ìœ ì§€ ë˜ëŠ” ê°’ì´ê¸° ë•Œë¬¸ì— í˜„ì¬ í˜ì´ì§€ ì˜ input value ë¥¼ ê¸°ë°˜ ìœ¼ë¡œ í•œ session state ì˜ ê²½ìš°
# í˜„ì¬ í˜ì´ì§€ -> ë‹¤ë¥¸ í˜ì´ì§€ -> í˜„ì¬ í˜ì´ì§€ ë¡œ ì´ë™ì‹œ ë¬¸ì œê°€ ë°œìƒí•  ì†Œì§€ê°€ ìˆë‹¤
# https://pypi.org/e1.sitemap.xml auto, wind, django
message_group_key = 'site_gpt'

with st.sidebar:
    url = st.text_input("Write down a URL", placeholder="https://www.google.com")
    url_filter = st.text_input("Write a filter string", placeholder="index")

    # í˜ì´ì§€ ì´ˆê¸°í™” ì‹œ url ì´ ì—†ì„ ê²½ìš° session_state ì´ˆê¸°í™”
    if not url:
        set_session('run_search_sitemap', False)

    if st.button("Search SiteMap"):
        on_button_click(url)

if get_session('run_search_sitemap'):
    retriever = find_docs_by_sitemap(url, url_filter)

    if retriever is None:
        st.error("SiteMap Info Not Found")
        set_session('run_search_sitemap', False)
    else:
        message_group_key = f'${url}_{url_filter}'
        # text_input / chat_input ì˜ ì°¨ì´ì 
        # chat_input ì€ ì „ì†¡ì„ í•˜ë©´ ì…ë ¥ ê°’ì´ ì´ˆê¸°í™” ë˜ì§€ë§Œ text_input ì€ ê°’ì´ ì´ˆê¸°í™” ì•ˆë¨
        print_message('I`m ready! Ask Away', 'ai')
        print_message_history(message_group_key)

        query = st.chat_input("Ask question to the website")

        if query:
            print_message_and_save(message_group_key, query, 'human')

            # __get_answers ì˜ ê³¼ì •ì€ streaming ì´ ë˜ì–´ ì„œëŠ” ì•ˆë˜ê³  __pick_answer ì˜ ê³¼ì •ë§Œ streaming ì´ ë˜ì–´ì•¼ í•œë‹¤
            # ê·¸ë¦¬ê³  ì¶”ê°€ ì ìœ¼ë¡œ í™•ì¸ í•´ì•¼ í•  ì‚¬í•­ì´ ìˆëŠ”ë° í˜„ì¬ì˜ callback handler ì„¤ì • ì—ì„œ memory ì— ì €ì¥ëœ ì¤‘ê°„ ê³¼ì •ì´
            # streaming ë˜ëŠ” ê²½ìš°ê°€ ìˆëŠ” ë“¯ í•˜ë‹¤ ì¶”ê°€ ì ì¸ í™•ì¸ í•„ìš”
            chain = ({"docs": retriever, "question": RunnablePassthrough()}
                     | RunnableLambda(__get_answers)
                     | RunnableLambda(__pick_answer))

            # StreamingChatCallBackHandler ì—ì„œ ë©”ì‹œì§€ í‘œì‹œ í•˜ëŠ” ê²ƒì„ ë‹´ë‹¹
            with st.chat_message('ai'):
                resp = chain.invoke(query)

            # message_group_key ê°€ í•„ìš” í•˜ê¸° ë•Œë¬¸ì— StreamingChatCallBackHandler on_llm_end ì—ì„œ
            # save_message ë¥¼ í˜¸ì¶œ í•˜ëŠ” ê²ƒì´ ë¶ˆê°€ëŠ¥
            save_message(message_group_key, resp.content, 'ai')



